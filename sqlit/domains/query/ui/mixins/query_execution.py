"""Query execution helpers and actions."""

from __future__ import annotations

from typing import TYPE_CHECKING, Any

from sqlit.domains.explorer.ui.tree import db_switching as tree_db_switching
from sqlit.shared.ui.lifecycle import LifecycleHooksMixin
from sqlit.shared.ui.protocols import QueryMixinHost
from sqlit.shared.ui.spinner import Spinner

from .query_constants import MAX_FETCH_ROWS

if TYPE_CHECKING:
    from textual.worker import Worker

    from sqlit.domains.query.app.cancellable import CancellableQuery
    from sqlit.domains.query.app.query_service import QueryService
    from sqlit.domains.query.app.transaction import TransactionExecutor


class QueryExecutionMixin(LifecycleHooksMixin):
    """Mixin providing query execution actions."""

    _query_service: QueryService | None = None
    _query_service_db_type: str | None = None
    _query_worker: Worker[Any] | None = None
    _cancellable_query: CancellableQuery | None = None
    _transaction_executor: TransactionExecutor | None = None
    _transaction_executor_config: Any | None = None
    _query_spinner: Spinner | None = None
    _query_cursor_cache: dict[str, tuple[int, int]] | None = None
    _query_target_database: str | None = None
    _schema_worker: Any | None = None
    _schema_indexing: bool = False

    def action_execute_query(self: QueryMixinHost) -> None:
        """Execute the current query."""
        self._execute_query_common(keep_insert_mode=False)

    def action_execute_query_insert(self: QueryMixinHost) -> None:
        """Execute query in INSERT mode without leaving it."""
        self._execute_query_common(keep_insert_mode=True)

    def action_execute_query_atomic(self: QueryMixinHost) -> None:
        """Execute query atomically (wrapped in BEGIN/COMMIT with rollback on error)."""
        if not self.current_connection or not self.current_provider:
            self.notify("Connect to a server to execute queries", severity="warning")
            return

        query = self.query_input.text.strip()

        if not query:
            self.notify("No query to execute", severity="warning")
            return

        if hasattr(self, "_query_worker") and self._query_worker is not None:
            self._query_worker.cancel()

        self._start_query_spinner()

        self._query_worker = self.run_worker(
            self._run_query_atomic_async(query),
            name="query_execution_atomic",
            exclusive=True,
        )

    def _execute_query_common(self: QueryMixinHost, keep_insert_mode: bool) -> None:
        """Common query execution logic."""
        if not self.current_connection or not self.current_provider:
            self.notify("Connect to a server to execute queries", severity="warning")
            return

        query = self.query_input.text.strip()

        if not query:
            self.notify("No query to execute", severity="warning")
            return

        if hasattr(self, "_query_worker") and self._query_worker is not None:
            self._query_worker.cancel()

        self._start_query_spinner()

        self._query_worker = self.run_worker(
            self._run_query_async(query, keep_insert_mode),
            name="query_execution",
            exclusive=True,
        )

    def _start_query_spinner(self: QueryMixinHost) -> None:
        """Start the query execution spinner animation."""
        import time

        self.query_executing = True
        self._query_start_time = time.perf_counter()
        if self._query_spinner is not None:
            self._query_spinner.stop()
        self._query_spinner = Spinner(self, on_tick=lambda _: self._update_status_bar(), fps=30)
        self._query_spinner.start()
        self._update_footer_bindings()

    def _stop_query_spinner(self: QueryMixinHost) -> None:
        """Stop the query execution spinner animation."""
        self.query_executing = False
        if self._query_spinner is not None:
            self._query_spinner.stop()
            self._query_spinner = None

    def _get_history_store(self: QueryMixinHost) -> Any:
        store = getattr(self, "_history_store", None)
        if store is not None:
            return store
        return self.services.history_store

    def _get_query_service(self: QueryMixinHost, provider: Any) -> QueryService:
        if self._query_service is None or (
            self._query_service_db_type is not None
            and self._query_service_db_type != provider.metadata.db_type
        ):
            from sqlit.domains.query.app.query_service import DialectQueryAnalyzer, QueryService

            self._query_service = QueryService(
                self._get_history_store(),
                analyzer=DialectQueryAnalyzer(provider.dialect),
            )
            self._query_service_db_type = provider.metadata.db_type
        return self._query_service

    def _use_process_worker(self: QueryMixinHost, provider: Any) -> bool:
        runtime = getattr(self.services, "runtime", None)
        if not runtime or not getattr(runtime, "process_worker", False):
            return False
        return True

    def _get_process_worker_client(self: QueryMixinHost) -> Any | None:
        client = getattr(self, "_process_worker_client", None)
        if client is not None:
            self._touch_process_worker()
            return client
        try:
            from sqlit.domains.query.app.process_worker_client import ProcessWorkerClient

            client = ProcessWorkerClient()
            self._process_worker_client = client
            self._process_worker_client_error = None
            self._touch_process_worker()
            return client
        except Exception as exc:
            self._process_worker_client_error = str(exc)
            try:
                self.log.error(f"Failed to start process worker: {exc}")
            except Exception:
                pass
            return None

    def _close_process_worker_client(self: QueryMixinHost) -> None:
        client = getattr(self, "_process_worker_client", None)
        if client is None:
            return
        try:
            client.close()
        except Exception:
            pass
        self._process_worker_client = None
        self._clear_process_worker_auto_shutdown()

    def _touch_process_worker(self: QueryMixinHost) -> None:
        import time

        self._process_worker_last_used = time.monotonic()
        self._arm_process_worker_auto_shutdown()

    def _clear_process_worker_auto_shutdown(self: QueryMixinHost) -> None:
        timer = getattr(self, "_process_worker_idle_timer", None)
        if timer is not None:
            try:
                timer.stop()
            except Exception:
                pass
        self._process_worker_idle_timer = None

    def _arm_process_worker_auto_shutdown(self: QueryMixinHost) -> None:
        import time

        runtime = getattr(self.services, "runtime", None)
        if runtime is None:
            return
        auto_seconds = float(getattr(runtime, "process_worker_auto_shutdown_s", 0) or 0)
        if auto_seconds <= 0:
            self._clear_process_worker_auto_shutdown()
            return

        self._clear_process_worker_auto_shutdown()
        last_used = getattr(self, "_process_worker_last_used", None)
        if last_used is None and getattr(self, "_process_worker_client", None) is not None:
            last_used = time.monotonic()
            self._process_worker_last_used = last_used

        def _maybe_shutdown() -> None:
            if last_used is None:
                return
            if getattr(self, "query_executing", False):
                self._arm_process_worker_auto_shutdown()
                return
            if getattr(self, "_process_worker_last_used", None) != last_used:
                return
            self._close_process_worker_client()

        self._process_worker_idle_timer = self.set_timer(auto_seconds, _maybe_shutdown)

    def _schedule_process_worker_warm(self: QueryMixinHost) -> None:
        runtime = getattr(self.services, "runtime", None)
        if runtime is None or not getattr(runtime, "process_worker_warm_on_idle", False):
            return
        from sqlit.domains.shell.app.idle_scheduler import Priority, get_idle_scheduler

        scheduler = get_idle_scheduler()
        if scheduler is None:
            return
        scheduler.cancel_all(name="process-worker-warm")

        def _warm() -> None:
            if not getattr(self.services.runtime, "process_worker", False):
                return
            if not getattr(self.services.runtime, "process_worker_warm_on_idle", False):
                return
            self._get_process_worker_client()

        scheduler.request_idle_callback(
            _warm,
            priority=Priority.LOW,
            name="process-worker-warm",
        )

    def _cancel_process_worker_warm(self: QueryMixinHost) -> None:
        from sqlit.domains.shell.app.idle_scheduler import get_idle_scheduler

        scheduler = get_idle_scheduler()
        if scheduler is None:
            return
        scheduler.cancel_all(name="process-worker-warm")

    def _get_transaction_executor(self: QueryMixinHost, config: Any, provider: Any) -> Any:
        """Get or create a TransactionExecutor for the current connection."""
        from sqlit.domains.query.app.transaction import TransactionExecutor

        # Create new executor if none exists or if config changed
        if self._transaction_executor is None or self._transaction_executor_config != config:
            if self._transaction_executor is not None:
                self._transaction_executor.close()
            self._transaction_executor = TransactionExecutor(config=config, provider=provider)
            self._transaction_executor_config = config
        return self._transaction_executor

    def _reset_transaction_executor(self: QueryMixinHost) -> None:
        """Reset the transaction executor (e.g., on disconnect)."""
        if self._transaction_executor is not None:
            self._transaction_executor.close()
            self._transaction_executor = None
        self._transaction_executor_config = None

    def _on_disconnect(self: QueryMixinHost) -> None:
        """Handle disconnect lifecycle event."""
        parent_disconnect = getattr(super(), "_on_disconnect", None)
        if callable(parent_disconnect):
            parent_disconnect()
        self._reset_transaction_executor()
        self._close_process_worker_client()

    @property
    def in_transaction(self: QueryMixinHost) -> bool:
        """Whether we're currently in a transaction."""
        if self._transaction_executor is not None:
            return bool(self._transaction_executor.in_transaction)
        return False

    async def _run_query_async(self: QueryMixinHost, query: str, keep_insert_mode: bool) -> None:
        """Run query asynchronously using TransactionExecutor for transaction support."""
        import asyncio
        import time

        from sqlit.domains.query.app.multi_statement import (
            MultiStatementExecutor,
            split_statements,
        )
        from sqlit.domains.query.app.query_service import QueryResult, parse_use_statement
        from sqlit.domains.query.app.transaction import is_transaction_end, is_transaction_start

        provider = self.current_provider
        config = self.current_config

        if not provider or not config:
            self._display_query_error("Not connected")
            self._stop_query_spinner()
            return

        # If we have a target database from clicking a table in the tree,
        # use that database for the query execution (needed for Azure SQL)
        target_db = getattr(self, "_query_target_database", None)
        endpoint = config.tcp_endpoint
        current_db = endpoint.database if endpoint else ""
        if target_db and target_db != current_db:
            config = provider.apply_database_override(config, target_db)
        # Clear target database after use - it's only for the auto-generated query
        self._query_target_database = None

        # Apply active database to query execution (from USE statement or 'u' key)
        active_db = None
        if hasattr(self, "_get_effective_database"):
            active_db = self._get_effective_database()
        endpoint = config.tcp_endpoint
        current_db = endpoint.database if endpoint else ""
        if active_db and active_db != current_db and not target_db:
            config = provider.apply_database_override(config, active_db)

        # Handle USE database statements
        db_name = parse_use_statement(query)
        if db_name is not None:
            self._stop_query_spinner()
            self._display_non_query_result(0, 0)
            tree_db_switching.set_default_database(self, db_name)
            if keep_insert_mode:
                self._restore_insert_mode()
            return

        # Use TransactionExecutor for transaction-aware query execution
        executor = self._get_transaction_executor(config, provider)
        service = self._get_query_service(provider)

        # Check if this is a multi-statement query
        statements = split_statements(query)
        is_multi_statement = len(statements) > 1

        try:
            start_time = time.perf_counter()
            max_rows = self.services.runtime.max_rows or MAX_FETCH_ROWS

            use_process_worker = self._use_process_worker(provider)
            if use_process_worker and statements:
                statement = statements[0].strip()
                if self.in_transaction or is_transaction_start(statement) or is_transaction_end(statement):
                    use_process_worker = False

            if use_process_worker and not is_multi_statement:
                client = self._get_process_worker_client()
                if client is None:
                    error = getattr(self, "_process_worker_client_error", None)
                    if error:
                        self.notify(
                            f"Process worker unavailable; falling back. ({error})",
                            severity="error",
                            title="Process Worker",
                        )
                    else:
                        self.notify(
                            "Process worker unavailable; falling back.",
                            severity="error",
                            title="Process Worker",
                        )
                    use_process_worker = False

                if use_process_worker:
                    outcome = await asyncio.to_thread(client.execute, query, config, max_rows)
                    if outcome.cancelled:
                        return
                    if outcome.error:
                        self._display_query_error(outcome.error)
                        return

                    service._save_to_history(config.name, query)
                    result = outcome.result
                    elapsed_ms = outcome.elapsed_ms

                    if isinstance(result, QueryResult):
                        await self._display_query_results(
                            result.columns,
                            result.rows,
                            result.row_count,
                            result.truncated,
                            elapsed_ms,
                        )
                    else:
                        self._display_non_query_result(result.rows_affected, elapsed_ms)
                    if keep_insert_mode:
                        self._restore_insert_mode()
                    return

            if is_multi_statement:
                # Multi-statement execution with stacked results
                multi_executor = MultiStatementExecutor(executor)
                multi_result = await asyncio.to_thread(
                    multi_executor.execute,
                    query,
                    max_rows,
                )
                elapsed_ms = (time.perf_counter() - start_time) * 1000

                service._save_to_history(config.name, query)
                self._display_multi_statement_results(multi_result, elapsed_ms)
            else:
                # Single statement - existing behavior
                result = await asyncio.to_thread(
                    executor.execute,
                    query,
                    max_rows,
                )
                elapsed_ms = (time.perf_counter() - start_time) * 1000

                service._save_to_history(config.name, query)

                if isinstance(result, QueryResult):
                    await self._display_query_results(
                        result.columns, result.rows, result.row_count, result.truncated, elapsed_ms
                    )
                else:
                    self._display_non_query_result(result.rows_affected, elapsed_ms)

            if keep_insert_mode:
                self._restore_insert_mode()

        except RuntimeError as e:
            if "cancelled" in str(e).lower():
                pass  # Already handled by action_cancel_query
            else:
                self._display_query_error(str(e))
        except Exception as e:
            self._display_query_error(str(e))
        finally:
            self._stop_query_spinner()

    async def _run_query_atomic_async(self: QueryMixinHost, query: str) -> None:
        """Run query atomically (BEGIN/COMMIT with rollback on error)."""
        import asyncio
        import time

        from sqlit.domains.query.app.query_service import QueryResult
        from sqlit.domains.query.app.transaction import TransactionExecutor

        provider = self.current_provider
        config = self.current_config

        if not provider or not config:
            self._display_query_error("Not connected")
            self._stop_query_spinner()
            return

        # Apply active database if set
        active_db = None
        if hasattr(self, "_get_effective_database"):
            active_db = self._get_effective_database()
        endpoint = config.tcp_endpoint
        current_db = endpoint.database if endpoint else ""
        if active_db and active_db != current_db:
            config = provider.apply_database_override(config, active_db)

        # Create a dedicated executor for atomic execution
        executor = TransactionExecutor(config=config, provider=provider)
        service = self._get_query_service(provider)

        try:
            start_time = time.perf_counter()
            max_rows = self.services.runtime.max_rows or MAX_FETCH_ROWS
            result = await asyncio.to_thread(
                executor.atomic_execute,
                query,
                max_rows,
            )
            elapsed_ms = (time.perf_counter() - start_time) * 1000

            service._save_to_history(config.name, query)

            if isinstance(result, QueryResult):
                await self._display_query_results(
                    result.columns, result.rows, result.row_count, result.truncated, elapsed_ms
                )
            else:
                self._display_non_query_result(result.rows_affected, elapsed_ms)

            self.notify("Query executed atomically (committed)", severity="information")

        except Exception as e:
            self._display_query_error(f"Transaction rolled back: {e}")
        finally:
            executor.close()
            self._stop_query_spinner()

    def _restore_insert_mode(self: QueryMixinHost) -> None:
        """Restore INSERT mode after query execution (called on main thread)."""
        from sqlit.core.vim import VimMode

        self.vim_mode = VimMode.INSERT
        self.query_input.read_only = False
        self.query_input.focus()
        self._update_footer_bindings()
        self._update_vim_mode_visuals()

    def action_cancel_query(self: QueryMixinHost) -> None:
        """Cancel the currently running query."""
        if not getattr(self, "query_executing", False):
            self.notify("No query running")
            return

        client = getattr(self, "_process_worker_client", None)
        if client is not None:
            try:
                client.cancel_current()
            except Exception:
                pass

        if hasattr(self, "_cancellable_query") and self._cancellable_query is not None:
            self._cancellable_query.cancel()

        if hasattr(self, "_query_worker") and self._query_worker is not None:
            self._query_worker.cancel()
            self._query_worker = None

        self._stop_query_spinner()

        self._replace_results_table(["Status"], [("Query cancelled",)])

        self.notify("Query cancelled", severity="warning")

    def action_cancel_operation(self: QueryMixinHost) -> None:
        """Cancel any running operation (query or schema indexing)."""
        cancelled = False

        # Cancel query if running
        if getattr(self, "query_executing", False):
            # Cancel the cancellable query (closes dedicated connection)
            client = getattr(self, "_process_worker_client", None)
            if client is not None:
                try:
                    client.cancel_current()
                except Exception:
                    pass
            if hasattr(self, "_cancellable_query") and self._cancellable_query is not None:
                self._cancellable_query.cancel()

            if hasattr(self, "_query_worker") and self._query_worker is not None:
                self._query_worker.cancel()
                self._query_worker = None
            self._stop_query_spinner()

            # Update results table to show cancelled state
            self._replace_results_table(["Status"], [("Query cancelled",)])
            cancelled = True

        # Cancel schema indexing if running
        if getattr(self, "_schema_indexing", False):
            if hasattr(self, "_schema_worker") and self._schema_worker is not None:
                self._schema_worker.cancel()
                self._schema_worker = None
            self._stop_schema_spinner()
            cancelled = True

        if cancelled:
            self.notify("Operation cancelled", severity="warning")
        else:
            self.notify("No operation running")

    def action_clear_query(self: QueryMixinHost) -> None:
        """Clear the query input."""
        self.query_input.text = ""

    def action_new_query(self: QueryMixinHost) -> None:
        """Start a new query (clear input and results)."""
        self.query_input.text = ""
        self._replace_results_table([], [])

    def action_show_history(self: QueryMixinHost) -> None:
        """Show query history for the current connection."""
        if not self.current_config:
            self.notify("Not connected", severity="warning")
            return

        from ..screens import QueryHistoryScreen

        history_store = self._get_history_store()
        starred_store = self.services.starred_store
        history = history_store.load_for_connection(self.current_config.name)
        starred = starred_store.load_for_connection(self.current_config.name)
        self.push_screen(
            QueryHistoryScreen(history, self.current_config.name, starred),
            self._handle_history_result,
        )

    def _handle_history_result(self: QueryMixinHost, result: Any) -> None:
        """Handle the result from the history screen."""
        if result is None:
            return

        action, data = result
        if action == "select":
            # Initialize cursor cache if needed
            if self._query_cursor_cache is None:
                self._query_cursor_cache = {}
            cursor_cache = self._query_cursor_cache

            # Save current query's cursor position before switching
            current_query = self.query_input.text
            if current_query:
                cursor_cache[current_query] = self.query_input.cursor_location

            # Set new query text
            self.query_input.text = data

            # Restore cursor position if we have it cached, otherwise go to end
            if data in cursor_cache:
                self.query_input.cursor_location = cursor_cache[data]
            else:
                # Move cursor to end of query
                lines = data.split("\n")
                last_line = len(lines) - 1
                last_col = len(lines[-1]) if lines else 0
                self.query_input.cursor_location = (last_line, last_col)

            # Focus query input - this triggers on_descendant_focus which updates footer bindings
            self.query_input.focus()
        elif action == "delete":
            self._delete_history_entry(data)
            self.action_show_history()
        elif action == "toggle_star":
            self._toggle_star(data)
            self.action_show_history()

    def _delete_history_entry(self: QueryMixinHost, timestamp: str) -> None:
        """Delete a specific history entry by timestamp."""
        if not self.current_config:
            return
        self._get_history_store().delete_entry(self.current_config.name, timestamp)

    def _toggle_star(self: QueryMixinHost, query: str) -> None:
        """Toggle star status for a query."""
        if not self.current_config:
            return

        is_now_starred = self.services.starred_store.toggle_star(self.current_config.name, query)
        if is_now_starred:
            self.notify("Query starred")
        else:
            self.notify("Query unstarred")
